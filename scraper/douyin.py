# douyin_scraper.py
# æŠ–éŸ³çƒ­æœæ‰“å¼€ç½‘ç«™éƒ½æ²¡æœ‰å›¾ç‰‡çš„ï¼Œå› æ­¤ä¸ä¿å­˜avatar
# -*- coding: utf-8 -*-
from __future__ import annotations
import os
from typing import Any, Dict, List, Optional
from urllib.parse import quote
from datetime import datetime

import requests


class DouyinHotSpider:
    """
    æŠ–éŸ³çƒ­æ¦œçˆ¬è™«
    ä½¿ç”¨æ–¹å¼ï¼š
        spider = DouyinHotSpider()
        items = spider.run()
    æ¯æ¡ item è‡³å°‘åŒ…å«ï¼š
        title, url, heat_value, sentence_id, scraped_at
    """

    def __init__(
        self,
        url: Optional[str] = None,
        ua: Optional[str] = None,
        cookie: Optional[str] = None,
    ) -> None:
        # æ”¯æŒä»Žå¤–é¢ä¼ ï¼Œä¹Ÿæ”¯æŒè¯»çŽ¯å¢ƒå˜é‡
        self.url = url or os.getenv(
            "DOUYIN_HOT_URL",
            "https://www.douyin.com/aweme/v1/web/hot/search/list/?device_platform=webapp&aid=6383&channel=channel_pc_web&detail_list=1&source=6&main_billboard_count=5&update_version_code=170400&pc_client_type=1&pc_libra_divert=Mac&support_h265=1&support_dash=1&cpu_core_num=8&version_code=170400&version_name=17.4.0&cookie_enabled=true&screen_width=1512&screen_height=982",
        )
        self.ua = ua or os.getenv(
            "DOUYIN_UA",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.6 Safari/605.1.15",
        )
        self.cookie = cookie or os.getenv("DOUYIN_COOKIE", "")

    # ---------- å†…éƒ¨å·¥å…· ----------
    def _headers(self) -> Dict[str, str]:
        return {
            "User-Agent": self.ua,
            "Accept": "application/json, text/plain, */*",
            "Referer": "https://www.douyin.com/hot",
            "Cookie": self.cookie,
        }

    def _proxies(self) -> Optional[Dict[str, str]]:
        # çŽ¯å¢ƒå˜é‡æŽ§åˆ¶æ˜¯å¦èµ°ä»£ç†
        if os.getenv("USE_PROXY", "").lower() in ("1", "true", "yes"):
            proxy = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
            if proxy:
                return {"http": proxy, "https": proxy}
        return None

    @staticmethod
    def _build_url(sentence_id: str, word: str) -> str:
        """æž„é€ å¯ç‚¹å‡»çš„çƒ­æ¦œè¯¦æƒ…åœ°å€"""
        return f"https://www.douyin.com/hot/{sentence_id}/{quote(word, safe='')}"

    # ---------- æ ¸å¿ƒæ­¥éª¤ï¼šè¯·æ±‚ + è§£æž ----------
    def fetch_json(self) -> Dict[str, Any]:
        """è¯·æ±‚æŽ¥å£ï¼Œæ‹¿åˆ°åŽŸå§‹ JSON"""
        resp = requests.get(
            self.url,
            headers=self._headers(),
            timeout=20,
            proxies=self._proxies(),
        )
        resp.raise_for_status()
        return resp.json()

    def parse_items(self, payload: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»Ž JSON é‡ŒæŠ½å‡ºæˆ‘ä»¬è¦çš„å­—æ®µ"""
        data = payload.get("data", {}) if isinstance(payload, dict) else {}
        word_list = data.get("word_list", []) or []

        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        items: List[Dict[str, Any]] = []

        for item in word_list:
            word = item.get("word")
            sentence_id = item.get("sentence_id")
            if not (word and sentence_id):
                continue

            hot_value = item.get("hot_value")
            items.append(
                {
                    "title": str(word),
                    "url": self._build_url(str(sentence_id), str(word)),
                    "heat_value": hot_value,
                    "sentence_id": str(sentence_id),
                    "scraped_at": now,
                }
            )

        # æŒ‰çƒ­åº¦ä»Žé«˜åˆ°ä½Ž
        items.sort(key=lambda x: (x.get("heat_value") or 0), reverse=True)
        return items

    # ---------- å¯¹å¤–å…¥å£ ----------
    def run(self) -> List[Dict[str, Any]]:
        """ä¸€é”®è·‘å®Œ"""
        payload = self.fetch_json()
        return self.parse_items(payload)


# æµ‹è¯•ç”¨
if __name__ == "__main__":
    spider = DouyinHotSpider()
    hot_items = spider.run()
    for i, item in enumerate(hot_items, 1):
        print(f"{i}. {item['title']}  ðŸ”¥{item['heat_value']}")
        print(f"   id={item['sentence_id']}  url={item['url']}  at={item['scraped_at']}")